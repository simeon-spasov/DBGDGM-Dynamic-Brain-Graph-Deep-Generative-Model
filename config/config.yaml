defaults:
  - override /hydra/job_logging: none
  - override /hydra/hydra_logging: none

hydra:
  output_subdir: null
  run:
    dir: .

####################################################################################
####################################################################################

experiment:
  run: 0               # experiment run
  prefix: null          # experiment name
  is_gpu: False        # use GPU
  gpu_number: 0        # number of GPU
  seed: 123456         # seed for random number generators
  wb_logging: True     # log experiments with Weights and Biases
  wb_project: DEEP GEN # name of project for Weights and Biases

data:
  data_dir: ./data     # data directory 
  name: synthetic      # dataset name
  valid_prop: 0.10     # proportion validation data
  test_prop: 0.10      # proportion test data
  batch_size: 2        # batch size
  num_pos_edges: 100   # number of positive edges to same
  num_neg_edges: 100   # number of negative edges to same
  num_workers: 0       # number of CPUs to use for loading data

model:
  name: dynamic_graph   # model name
  num_communities: 3    # number of communities
  alpha_dim: 10         # dimension of alpha
  alpha_std: 0.1        # standard deviation of alpha
  beta_dim: 14          # dimension of beta
  phi_dim: 17           # dimension of phi
  tau: 1.0              # temperature of Gumbel Softmax distribution

loss:
  name: elbo            # name of loss
  gamma_alpha: 1.0      # weight for kl alpha
  gamma_beta: 1.0       # weight for kl beta
  gamma_phi: 1.0        # weight for kl phi
  gamma_z: 1.0          # weight for kl z
  edge_balance: True    # 

train:
  num_epochs: 20        # number of epochs to train
  learning_rate: 1e-3   # learning rate
  warmup: 10            # number of warm-up epochs (kl = 0)
  anneal_after: 100     # number of epochs before temperature annealing
  min_tau: 0.1          # minimum value to anneal temperature
  anneal_rate: 1e-5     # temperature anneal rate
  checkpoint_best: True # save the model with the lowest validation loss
  valid_every: 1        # frequency of model validation
  verbose: True         # print training output to terminal